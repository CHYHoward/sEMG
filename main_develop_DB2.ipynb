{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "# Save/Load as mat.\n",
    "from scipy.io import savemat, loadmat\n",
    "import h5py\n",
    "import mat73 # https://github.com/skjerns/mat7.3\n",
    "\n",
    "# Progress Bar\n",
    "from rich.progress import track\n",
    "from rich.progress import Progress\n",
    "\n",
    "# Other\n",
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import scipy.signal as signal\n",
    "import time\n",
    "\n",
    "# User-defined\n",
    "from mat2np_segment_all_subject import *\n",
    "from dsp_preprocess import *\n",
    "from dataset_parser import *\n",
    "from models import *\n",
    "from feature_extractor import *\n",
    "from set_args import *\n",
    "from train_test_process import *\n",
    "from vit import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "----------------------------------------------------------------------\n",
      "Database: NinaPro  DB2\n",
      "Number of subjects:  1  -> [1] subject\n",
      "Number of  exercises:  3  -> [1, 2, 3] exercise\n",
      "Number of gestures:  49, and we excludes 'rest' class\n",
      "----------------------------------------------------------------------\n",
      "Sampling rate:  2000  (sps)\n",
      "Number of channels:  12\n",
      "Window size:  400  (samples) =  200.0  (ms)\n",
      "Window step:  200  (samples) =  100.0  (ms)\n",
      "----------------------------------------------------------------------\n",
      "Device:  cuda:0\n",
      "Feature extraction:  False\n",
      "Model type:  ViT\n",
      "Model PATH:  ./Results/Lastest_results/ViT.pth\n",
      "Load model:  True\n",
      "Number of epochs:  20\n",
      "Batch size:  512\n",
      "Learning rate:  0.001\n",
      "----------------------------------------------------------------------\n",
      "======================================================================\n",
      "\n",
      "subject_list = [1]\n",
      "exercise_list = [1, 2, 3]\n",
      "fs = 2000\n",
      "num_channel = 12\n",
      "window_size_sec = 0.2\n",
      "window_step_sec = 0.1\n",
      "type_filter = none\n",
      "type_norm = mvc\n",
      "num_epoch = 20\n",
      "batch_size = 512\n",
      "lr = 0.001\n",
      "database = DB2\n",
      "model_type = ViT\n",
      "en_train = True\n",
      "load_model = True\n",
      "class_rest = False\n",
      "feat_extract = False\n",
      "load_dataset = True\n",
      "save_dataset = False\n",
      "log_name = Lastest_results\n"
     ]
    }
   ],
   "source": [
    "set_seed(87)\n",
    "\n",
    "raw_args = [\n",
    "    '--subject_list=1',\n",
    "    # '--exercise_list=1,2,3',\n",
    "    '--window_size_sec=0.2',\n",
    "    '--window_step_sec=0.1',\n",
    "    # '--type_filter=BPF_20_200'\n",
    "    # '--type_norm=mvc'\n",
    "    '--num_epoch=20',\n",
    "    '--batch_size=512',\n",
    "    '--model_type=ViT',\n",
    "    '--lr=0.001',\n",
    "    '--en_train',\n",
    "    '--load_dataset'\n",
    "    # '--save_dataset'\n",
    "]\n",
    "\n",
    "args = get_args(raw_args)\n",
    "window_size, window_step, number_gesture, model_PATH, device = get_args_info(args)\n",
    "\n",
    "for key, value in vars(args).items():\n",
    "    print(f\"{key} = {value}\")\n",
    "    exec(\"{} = args.{}\".format(key,key))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Loading saved train dataset in ./Dataset/DB2/\n",
      "Loading saved valid dataset in ./Dataset/DB2/\n",
      "Loading saved test dataset in ./Dataset/DB2/\n",
      "----------------------------------------------------------------------\n",
      "Number of train data: 254869\n",
      "Number of valid data: 81360\n",
      "Number of test  data: 167941\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader = train_test_split_DataLoader(\\\n",
    "                                            batch_size=batch_size, \\\n",
    "                                            subject_list=subject_list, \\\n",
    "                                            exercise_list=exercise_list, \\\n",
    "                                            fs=fs, \\\n",
    "                                            window_size=window_size, \\\n",
    "                                            window_step=window_step, \\\n",
    "                                            num_channel=num_channel, \\\n",
    "                                            feat_extract=feat_extract, \\\n",
    "                                            class_rest=class_rest, \\\n",
    "                                            load_dataset = load_dataset, \\\n",
    "                                            save_dataset = save_dataset\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(args,model,model_PATH,train_loader,valid_loader,device,optimizer,criterion):\n",
    "    # Print the model summary\n",
    "    summary(model, (train_loader.dataset[0][0].shape))\n",
    "    \n",
    "    # model.load_state_dict(torch.load(model_PATH)) # Pretrained model\n",
    "\n",
    "    t_start = time.time()\n",
    "    # with Progress(console=Console(file=sys.stderr)) as progress:\n",
    "    #with Progress() as progress:\n",
    "    # task1 = progress.add_task(\"[cyan]Epoch: \", total=args.num_epoch)\n",
    "\n",
    "    loss_best = float(\"inf\")\n",
    "    not_better_count = 0    \n",
    "    # print('', end='', flush=True)\n",
    "    for epoch in range(args.num_epoch):\n",
    "        end_type = '\\n' if epoch==args.num_epoch-1 else '\\r'\n",
    "        # end_type = '\\n'\n",
    "        \n",
    "        # Training Stage\n",
    "        model.train() # Make sure the model is in train mode before training.\n",
    "        # task2 = progress.add_task(\"[green][Train: ]\", total=len(train_loader))\n",
    "        running_loss_train = 0.0\n",
    "        running_acc_train = 0.0\n",
    "        n_train = 0\n",
    "        for i, (emg_sample, gesture_gold) in enumerate(train_loader):\n",
    "            emg_sample = emg_sample.to(device) # input\n",
    "            gesture_gold = gesture_gold.to(device) # Output\n",
    "\n",
    "            if args.model_type == \"ViT\":\n",
    "                # emg_sample = torch.unsqueeze(emg_sample.permute(0,2,1), dim=3)  # shape: (B, C, W, F) = (128, 12, 400, 1)\n",
    "                emg_sample = emg_sample.permute(0,2,1)  # shape: (B, C, 1*W*F) \n",
    "\n",
    "            gesture_pred = model(emg_sample)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(gesture_pred,gesture_gold)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss_train += loss.detach().item()*emg_sample.shape[0]\n",
    "            num_correct = (torch.argmax(gesture_pred, dim=1)==gesture_gold).sum()\n",
    "            running_acc_train += num_correct\n",
    "            n_train += emg_sample.shape[0]\n",
    "            # progress.update(task2, advance=1,description=\"[green][Train: %3d] [Train loss: %3.3f] [Train acc: %3.2f %%]: \" % (i+1,running_loss_train/n_train, 100*running_acc_train/n_train))\n",
    "            \n",
    "        # print(\"[Train: %3d] [Train loss: %3.3f] [Train acc: %3.2f %%]: \" % (i+1,running_loss_train/n_train, 100*running_acc_train/n_train), end=end_type)\n",
    "        # progress.remove_task(task2)\n",
    "\n",
    "        # Validation Stage\n",
    "        model.eval() # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
    "        # task3 = progress.add_task(\"[red]Validate \", total=len(valid_loader))\n",
    "        running_loss_valid = 0.0\n",
    "        running_acc_valid = 0.0\n",
    "        n_valid = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (emg_sample, gesture_gold) in enumerate(valid_loader):\n",
    "                emg_sample = emg_sample.to(device) # input\n",
    "\n",
    "                if args.model_type == \"ViT\":\n",
    "                    # emg_sample = torch.unsqueeze(emg_sample.permute(0,2,1), dim=3)  # shape: (B, C, W, F) = (128, 12, 400, 1)\n",
    "                    emg_sample = emg_sample.permute(0,2,1)  # shape: (B, C, 1*W*F)\n",
    "\n",
    "                gesture_gold = gesture_gold.to(device) # Output\n",
    "                gesture_pred = model(emg_sample)\n",
    "\n",
    "                loss = criterion(gesture_pred,gesture_gold)\n",
    "\n",
    "                running_loss_valid += loss.detach().item()*emg_sample.shape[0]\n",
    "                num_correct = (torch.argmax(gesture_pred, dim=1)==gesture_gold).sum() # torch.mean((torch.argmax(gesture_pred, dim=1) == labels).float()\n",
    "                \n",
    "\n",
    "                running_acc_valid += num_correct\n",
    "                n_valid += emg_sample.shape[0]\n",
    "                # progress.update(task3, advance=1,description=\"[red][Validate: %3d] [Valid loss: %3.3f] [Valid acc: %3.2f %%]: \" % (i+1, running_loss_valid/n_valid, 100*running_acc_valid/n_valid))\n",
    "            # print(\"[Valid: %3d] [Valid loss: %3.3f] [Valid acc: %3.2f %%]: \" % (i+1, running_loss_valid/n_valid, 100*running_acc_valid/n_valid),  end=end_type)\n",
    "        # progress.remove_task(task3)\n",
    "        \n",
    "        # Finishing a epoch\n",
    "        # progress.update(task1, advance=1,description=\"[cyan][Epoch: %3d] [Train loss: %3.3f acc: %3.2f %%] [Valid loss: %3.3f acc: %3.2f %%]\" \n",
    "        #                 %(epoch+1, running_loss_train/n_train, 100*running_acc_train/n_train, running_loss_valid/n_valid, 100*running_acc_valid/n_valid))\n",
    "        print(\"[Epoch: %3d / %d] [Train loss: %3.3f acc: %4.2f] [Valid loss: %3.3f acc: %4.2f]\" \n",
    "                        %(epoch+1, args.num_epoch, running_loss_train/n_train, 100*running_acc_train/n_train, running_loss_valid/n_valid, 100*running_acc_valid/n_valid),  end=end_type, flush=True)\n",
    "\n",
    "        print(model.layers[10].weight)\n",
    "        \n",
    "        # Save model or not \n",
    "        if running_loss_valid < loss_best:\n",
    "            loss_best = running_loss_valid\n",
    "            # print(\"New best loss in valid => Saving the model @ %s\", PATH)\n",
    "            torch.save(model.state_dict(), model_PATH)\n",
    "            not_better_count = 0\n",
    "        else:\n",
    "            not_better_count = not_better_count+1\n",
    "        if not_better_count > 10 and epoch>30:\n",
    "            break\n",
    "    \n",
    "    t_end = time.time()\n",
    "    print(\"Elasped training time: \", t_end - t_start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchsummary. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchsummary/torchsummary.py:140\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 140\u001b[0m         _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mto(device)(\u001b[39m*\u001b[39;49mx, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[0;32m/home/remote/@LH-ACCESS.EE.NTU.EDU.TW/61/d09_ciwade870307-1000008/EMG_HGR/vit.py:108\u001b[0m, in \u001b[0;36mViT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 108\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_patch_embedding(x)\n\u001b[1;32m    109\u001b[0m     batch_size, num_patch, _ \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (800x12 and 400x32)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/remote/LDAP/d09_ciwade870307-1000008/EMG_HGR/main_develop_DB2.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.112.20.131/home/remote/LDAP/d09_ciwade870307-1000008/EMG_HGR/main_develop_DB2.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Model Training and Validation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.112.20.131/home/remote/LDAP/d09_ciwade870307-1000008/EMG_HGR/main_develop_DB2.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39men_train:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B140.112.20.131/home/remote/LDAP/d09_ciwade870307-1000008/EMG_HGR/main_develop_DB2.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     train_process(args,model,model_PATH,train_loader,valid_loader,device,optimizer,criterion)\n",
      "\u001b[1;32m/home/remote/LDAP/d09_ciwade870307-1000008/EMG_HGR/main_develop_DB2.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.112.20.131/home/remote/LDAP/d09_ciwade870307-1000008/EMG_HGR/main_develop_DB2.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_process\u001b[39m(args,model,model_PATH,train_loader,valid_loader,device,optimizer,criterion):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.112.20.131/home/remote/LDAP/d09_ciwade870307-1000008/EMG_HGR/main_develop_DB2.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Print the model summary\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B140.112.20.131/home/remote/LDAP/d09_ciwade870307-1000008/EMG_HGR/main_develop_DB2.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     summary(model, (train_loader\u001b[39m.\u001b[39;49mdataset[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.112.20.131/home/remote/LDAP/d09_ciwade870307-1000008/EMG_HGR/main_develop_DB2.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# model.load_state_dict(torch.load(model_PATH)) # Pretrained model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.112.20.131/home/remote/LDAP/d09_ciwade870307-1000008/EMG_HGR/main_develop_DB2.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     t_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchsummary/torchsummary.py:143\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    142\u001b[0m     executed_layers \u001b[39m=\u001b[39m [layer \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m summary_list \u001b[39mif\u001b[39;00m layer\u001b[39m.\u001b[39mexecuted]\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    144\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to run torchsummary. See above stack traces for more details. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExecuted layers up to: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(executed_layers)\n\u001b[1;32m    146\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m hooks \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchsummary. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "# Training Setup\n",
    "if args.model_type == \"ViT\":\n",
    "    # TNet\n",
    "    num_patch = args.num_channel\n",
    "    patch_size = window_size\n",
    "    model = ViT(num_patch,patch_size).to(device)\n",
    "else:\n",
    "    model = eval(f\"{args.model_type}(number_gesture=number_gesture, class_rest=args.class_rest)\").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.00) \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Model Training and Validation\n",
    "if args.en_train:\n",
    "    train_process(args,model,model_PATH,train_loader,valid_loader,device,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_process(model,model_PATH,test_loader,device,criterion,load_model,model_type):\n",
    "    if load_model == True:\n",
    "        print(\"Loading the trained model on th path of: \",model_PATH)\n",
    "        model.load_state_dict(torch.load(model_PATH))\n",
    "        \n",
    "\n",
    "    # with Progress() as progress:\n",
    "    # Testing Stage\n",
    "    model.eval() # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
    "    # task4 = progress.add_task(\"[blue]Batch \", total=len(test_loader))\n",
    "    running_loss_test = 0.0\n",
    "    running_acc_test = 0.0\n",
    "    n_test = 0\n",
    "\n",
    "    y_pred = []\n",
    "    y_gold = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (emg_sample, gesture_gold) in enumerate(test_loader):\n",
    "            emg_sample = emg_sample.to(device) # input\n",
    "            gesture_gold = gesture_gold.to(device) # Output\n",
    "\n",
    "            if model_type == \"ViT\":\n",
    "                # emg_sample = torch.unsqueeze(emg_sample.permute(0,2,1), dim=3)  # shape: (B, C, W, F) = (128, 12, 400, 1)\n",
    "                emg_sample = emg_sample.permute(0,2,1)  # shape: (B, C, 1*W*F)\n",
    "            gesture_pred = model(emg_sample)\n",
    "\n",
    "            y_pred.extend(gesture_pred.argmax(dim=-1).view(-1).detach().cpu().numpy())       # 將preds預測結果detach出來，並轉成numpy格式       \n",
    "            y_gold.extend(gesture_gold.view(-1).detach().cpu().numpy())      # target是ground-truth的labe\n",
    "            \n",
    "            loss = criterion(gesture_pred,gesture_gold)\n",
    "\n",
    "            running_loss_test += loss.detach().item()*emg_sample.shape[0]\n",
    "            num_correct = (torch.argmax(gesture_pred, dim=1)==gesture_gold).sum()\n",
    "            running_acc_test += num_correct\n",
    "            n_test += emg_sample.shape[0]\n",
    "\n",
    "            # progress.update(task4, advance=1,description=\"[blue][Test loss: %3.3f] [Test acc: %3.2f %%]: \" % (running_loss_test/n_test, 100*running_acc_test/n_test))\n",
    "        print(\"[Test loss: %3.3f] [Test acc: %3.2f %%] \" % (running_loss_test/n_test, 100*running_acc_test/n_test), flush=True)\n",
    "\n",
    "    # Print the model summary\n",
    "    # summary(model, (emg_sample.shape[1:]))\n",
    "\n",
    "    return np.array(y_pred), np.array(y_gold) # (num_test,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained model on th path of:  ./Models/CNN_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test loss: 2.486] [Test acc: 32.23 %] \n"
     ]
    }
   ],
   "source": [
    "# Model Testing\n",
    "y_pred, y_gold = test_process(model,model_PATH,test_loader,device,criterion,args.load_model,args.model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emg_sample, gesture_gold = valid_loader.dataset[0:1000]\n",
    "# gesture_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_seg_np = \"Dataset/DB2/DB2_np/DB2_s_1/exercise_1/trial_1/\"\n",
    "# fileNames = [PATH_seg_np+i for i in os.listdir(PATH_seg_np)]\n",
    "# for fileName in fileNames:\n",
    "#     print(fileName)\n",
    "#     emg_sample_filter_norm_seg_batch, gesture_label_batch = dataset_filter_normalize_segementation(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (7): ReLU()\n",
      "  (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (9): Flatten(start_dim=1, end_dim=-1)\n",
      "  (10): Linear(in_features=576, out_features=49, bias=True)\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[-0.0404, -0.0249,  0.0367,  ...,  0.0387,  0.0014,  0.0178],\n",
      "        [-0.0411,  0.0054,  0.0306,  ..., -0.0009,  0.0060, -0.0046],\n",
      "        [-0.0180,  0.0207,  0.0178,  ..., -0.0257,  0.0403, -0.0019],\n",
      "        ...,\n",
      "        [-0.0348,  0.0352, -0.0037,  ...,  0.0294,  0.0153,  0.0311],\n",
      "        [-0.0153,  0.0129,  0.0322,  ..., -0.0247,  0.0204,  0.0350],\n",
      "        [-0.0020, -0.0388,  0.0375,  ..., -0.0233, -0.0280, -0.0178]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = eval(f\"{args.model_type}(number_gesture=number_gesture, class_rest=args.class_rest)\").to(device)\n",
    "# model.load_state_dict(torch.load(model_PATH))\n",
    "print(model.layers)\n",
    "print(model.layers[10].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/remote/LDAP/d09_ciwade870307-1000008/EMG_HGR/main_develop_DB2.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.112.20.131/home/remote/LDAP/d09_ciwade870307-1000008/EMG_HGR/main_develop_DB2.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m n_test \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m emg_sample\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.112.20.131/home/remote/LDAP/d09_ciwade870307-1000008/EMG_HGR/main_develop_DB2.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m# progress.update(task4, advance=1,description=\"[blue][Test loss: %3.3f] [Test acc: %3.2f %%]: \" % (running_loss_test/n_test, 100*running_acc_test/n_test))\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B140.112.20.131/home/remote/LDAP/d09_ciwade870307-1000008/EMG_HGR/main_develop_DB2.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[Test loss: \u001b[39m\u001b[39m%3.3f\u001b[39;00m\u001b[39m] [Test acc: \u001b[39m\u001b[39m%3.2f\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (running_loss_test\u001b[39m/\u001b[39;49mn_test, \u001b[39m100\u001b[39m\u001b[39m*\u001b[39mrunning_acc_test\u001b[39m/\u001b[39mn_test), flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "model.eval() # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
    "# task4 = progress.add_task(\"[blue]Batch \", total=len(test_loader))\n",
    "running_loss_test = 0.0\n",
    "running_acc_test = 0.0\n",
    "n_test = 0\n",
    "\n",
    "y_pred = []\n",
    "y_gold = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    emg_sample, gesture_gold = test_loader.dataset[8000:9000]\n",
    "    emg_sample = emg_sample.to(device) # input\n",
    "    gesture_gold = gesture_gold.to(device) # Output\n",
    "    # print(emg_sample)\n",
    "    \n",
    "    # print(gesture_gold)\n",
    "\n",
    "    if model_type == \"ViT\":\n",
    "        # emg_sample = torch.unsqueeze(emg_sample.permute(0,2,1), dim=3)  # shape: (B, C, W, F) = (128, 12, 400, 1)\n",
    "        emg_sample = emg_sample.permute(0,2,1)  # shape: (B, C, 1*W*F)\n",
    "    gesture_pred = model(emg_sample)\n",
    "    # print(gesture_pred)\n",
    "\n",
    "    y_pred.extend(gesture_pred.argmax(dim=-1).view(-1).detach().cpu().numpy())       # 將preds預測結果detach出來，並轉成numpy格式       \n",
    "    y_gold.extend(gesture_gold.view(-1).detach().cpu().numpy())      # target是ground-truth的labe\n",
    "    \n",
    "    loss = criterion(gesture_pred,gesture_gold)\n",
    "\n",
    "    running_loss_test += loss.detach().item()*emg_sample.shape[0]\n",
    "    num_correct = (torch.argmax(gesture_pred, dim=1)==gesture_gold).sum()\n",
    "    running_acc_test += num_correct\n",
    "    n_test += emg_sample.shape[0]\n",
    "\n",
    "        # progress.update(task4, advance=1,description=\"[blue][Test loss: %3.3f] [Test acc: %3.2f %%]: \" % (running_loss_test/n_test, 100*running_acc_test/n_test))\n",
    "    print(\"[Test loss: %3.3f] [Test acc: %3.2f %%] \" % (running_loss_test/n_test, 100*running_acc_test/n_test), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion Matrix')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_gold, y_pred)\n",
    "\n",
    "# Plot the confusion matrix using seaborn and matplotlib\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.set(font_scale=0.6)\n",
    "sns.heatmap(cm, annot=False, fmt='d', cbar=False, square=True, xticklabels=True, yticklabels=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
