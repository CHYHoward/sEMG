{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "# Save/Load as mat.\n",
    "from scipy.io import savemat, loadmat\n",
    "import h5py\n",
    "import mat73 # https://github.com/skjerns/mat7.3\n",
    "\n",
    "# Progress Bar\n",
    "from rich.progress import track\n",
    "from rich.progress import Progress\n",
    "\n",
    "# Other\n",
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import scipy.signal as signal\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from plot import *\n",
    "\n",
    "# User-defined\n",
    "from mat2np_segment_all_subject import *\n",
    "from dsp_preprocess import *\n",
    "from dataset_parser import *\n",
    "from models import *\n",
    "from feature_extractor import *\n",
    "from set_args import *\n",
    "from train_test_process import *\n",
    "from vit import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Filter =====================\n",
    "def butter_filter(x, type_filter=\"highpass\", cut_low=20, cut_high = 500, fs=2000, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    if type_filter==\"bandpass\":\n",
    "        normal_cut_low = [cut_low / nyq, cut_high / nyq]\n",
    "    else:\n",
    "        normal_cut_low = cut_low / nyq\n",
    "    sos = signal.butter(N=order, Wn=normal_cut_low, btype=type_filter, output='sos')\n",
    "    # y = signal.sosfilt(sos, x)\n",
    "    y = signal.sosfiltfilt(sos,x,axis=0)\n",
    "    return y\n",
    "\n",
    "def filter(x, type_filter=\"none\", cut_low=20, cut_high = 200, fs=2000, order=5):\n",
    "    if type_filter != 'none':\n",
    "        type_filter_name, cut_low, cut_high = type_filter.split('_')\n",
    "    else:\n",
    "        type_filter_name = \"none\"\n",
    "\n",
    "    if type_filter_name == \"none\":\n",
    "        y = x\n",
    "    elif type_filter_name == \"HPF\":\n",
    "        y = butter_filter(x, type_filter=\"highpass\", cut_low=float(cut_low), fs=fs, order=order)\n",
    "    elif type_filter_name == \"LPF\":\n",
    "        y = butter_filter(x, type_filter=\"lowpass\", cut_low=float(cut_low), fs=fs, order=order)\n",
    "    elif type_filter_name == \"BPF\":\n",
    "        y = butter_filter(x, type_filter=\"bandpass\", cut_low=float(cut_low), cut_high=float(cut_high), fs=fs, order=order)\n",
    "    else:\n",
    "        raise TypeError(f'{type_filter} is not defined in type_filter')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_filter_normalize_segementation(fileName, order, fs=2000, window_size = 400, window_step=200, num_channel=12, type_filter=\"BPF_20_200\", type_norm=\"mvc\"):\n",
    "    gesture_label  = np.array(int(fileName.split('/')[-1].split('.')[0].split('_')[1]))\n",
    "    emg_sample = np.load(fileName)\n",
    "\n",
    "    # Filtering and Normalization\n",
    "    emg_sample_filter = filter(emg_sample,type_filter=type_filter, fs=fs, order=order)    # whole_window_size * num_channel (e.g., LPF_200_, HPF_20_, ...)\n",
    "    emg_sample_filter_norm = normalization(emg_sample_filter, type_norm=type_norm)\n",
    "\n",
    "    # Sliding window segmentation\n",
    "    num_window = (np.floor((emg_sample_filter_norm.shape[0]-window_size)/window_step) + 1).astype(int)\n",
    "    emg_sample_filter_norm_seg_batch = None\n",
    "    gesture_label_batch = None\n",
    "    # emg_sample_filter_norm_seg_batch = np.zeros((num_window, window_size, num_channel))\n",
    "    # gesture_label_batch = np.zeros((num_window, 1))\n",
    "\n",
    "    for i in range(num_window):\n",
    "        emg_sample_filter_norm_seg = emg_sample_filter_norm[i*window_step:i*window_step+window_size]\n",
    "        emg_sample_filter_norm_seg_batch = handle_concatenation(emg_sample_filter_norm_seg_batch, emg_sample_filter_norm_seg.reshape(1,window_size,-1), axis=0)\n",
    "        gesture_label_batch = handle_concatenation(gesture_label_batch, gesture_label.reshape(1,-1), axis=0)\n",
    "        \n",
    "        # num_sample = emg_sample_filter_norm_seg.shape[0]\n",
    "        # emg_sample_filter_norm_seg_batch[i] = emg_sample_filter_norm_seg\n",
    "        # gesture_label_batch[i] = gesture_label\n",
    "\n",
    "    return emg_sample_filter_norm_seg_batch, gesture_label_batch  #shape: (num_window, window_size, num_channel); #shape: (num_window,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_subject = 1\n",
    "idx_exercise = 1\n",
    "idx_trial = 1\n",
    "\n",
    "PATH_seg_np = \"Dataset/DB2/DB2_np/DB2_s_{}/exercise_{}/trial_{}/\".format(idx_subject,idx_exercise,idx_trial)\n",
    "fileNames = sorted([PATH_seg_np+i for i in os.listdir(PATH_seg_np)])\n",
    "# print(sorted(fileNames))\n",
    "mean_all_gesture = 0\n",
    "for fileName in fileNames:\n",
    "    gesture = fileName.split(\"/\")[-4:]\n",
    "    emg_sample_dataset, gesture_label_dataset = dataset_filter_normalize_segementation(fileName, 3, fs=2000, window_size = 400, window_step=200, num_channel=12, type_filter=\"none\", type_norm=\"none\")\n",
    "    emg_sample_dataset_LPF1, _ = dataset_filter_normalize_segementation(fileName, 1 ,fs=2000, window_size = 400, window_step=200, num_channel=12, type_filter=\"LPF_20_\", type_norm=\"mu_law_0.1\")\n",
    "    emg_sample_dataset_LPF3, _ = dataset_filter_normalize_segementation(fileName, 1 ,fs=2000, window_size = 400, window_step=200, num_channel=12, type_filter=\"LPF_20_\", type_norm=\"mu_law_1\")\n",
    "    emg_sample_dataset_LPF5, _ = dataset_filter_normalize_segementation(fileName, 1 ,fs=2000, window_size = 400, window_step=200, num_channel=12, type_filter=\"LPF_20_\", type_norm=\"mu_law_256\")\n",
    "    amp_mean = np.mean(np.mean(abs(emg_sample_dataset),axis=1), axis=0)\n",
    "    # print(amp_mean)\n",
    "    # print(f\"{gesture[-1]}, Mean: {np.mean(amp_mean)}, Max amplitude: {np.max(emg_sample_dataset)}\")\n",
    "    mean_all_gesture += np.mean(amp_mean)\n",
    "    # plt.figure(figsize=(6,2))\n",
    "    # plt.hist(abs(emg_sample_dataset.reshape(-1)))\n",
    "    \n",
    "    # print(emg_sample_dataset.shape)\n",
    "    # plt.figure(figsize=(6,2))\n",
    "    # plt.plot(emg_sample_dataset[0])\n",
    "    # plt.title(gesture)\n",
    "print(f\"{PATH_seg_np} mean: {mean_all_gesture/len(fileNames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2,3],[4,5,6]]\n",
    "print(len(a))\n",
    "print(len(a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(emg_sample_dataset[0,:,0])\n",
    "plt.plot(emg_sample_dataset_LPF1[0,:,0])\n",
    "plt.plot(emg_sample_dataset_LPF3[0,:,0])\n",
    "plt.plot(emg_sample_dataset_LPF5[0,:,0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_subject = 40\n",
    "# idx_exercise = 3\n",
    "# idx_trial = 5\n",
    "\n",
    "for idx_subject in range(1,41):\n",
    "    for idx_trial in range(1,7):\n",
    "        for idx_exercise in range(1,4):\n",
    "            PATH_seg_np = \"Dataset/DB2/DB2_np/DB2_s_{}/exercise_{}/trial_{}/\".format(idx_subject,idx_exercise,idx_trial)\n",
    "            fileNames = sorted([PATH_seg_np+i for i in os.listdir(PATH_seg_np)])\n",
    "            # print(sorted(fileNames))\n",
    "            mean_all_gesture = 0\n",
    "            for fileName in fileNames:\n",
    "                gesture = fileName.split(\"/\")[-4:]\n",
    "                emg_sample_dataset, gesture_label_dataset = dataset_filter_normalize_segementation(fileName, fs=2000, window_size = 400, window_step=200, num_channel=12, type_filter=\"none\", type_norm=\"none\")\n",
    "                amp_mean = np.mean(np.mean(abs(emg_sample_dataset),axis=1), axis=0)\n",
    "                # print(amp_mean)\n",
    "                # print(f\"{gesture[-1]}, Mean: {np.mean(amp_mean)}, Max amplitude: {np.max(emg_sample_dataset)}\")\n",
    "                mean_all_gesture += np.mean(amp_mean)\n",
    "                # plt.figure(figsize=(6,2))\n",
    "                # plt.hist(abs(emg_sample_dataset.reshape(-1)))\n",
    "                \n",
    "                # print(emg_sample_dataset.shape)\n",
    "                # plt.figure(figsize=(6,2))\n",
    "                # plt.plot(emg_sample_dataset[0])\n",
    "                # plt.title(gesture)\n",
    "            print(f\"{PATH_seg_np} mean: {mean_all_gesture/len(fileNames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Normalization =====================\n",
    "def normalization(x, type_norm=\"mu_law\"):\n",
    "    # input x : numpy, shape: (window_size, num_channel)\n",
    "    # output y: numpy, shape: (window_size, num_channel)\n",
    "\n",
    "    if type_norm == \"none\":\n",
    "        y = x\n",
    "    elif type_norm == \"mvc\":    #  maximum voluntary contraction (MVC)\n",
    "        # mvc = 0.002479567551179044 # search over all train dataset (current MVC: 4.088872887106668)\n",
    "        mvc = 1e-5\n",
    "        y = x/mvc\n",
    "    elif type_norm == \"standardization\":\n",
    "        mean = np.mean(x,axis=0)\n",
    "        std = np.std(x,axis=0)\n",
    "        y = (x-mean)/std\n",
    "    elif type_norm == \"min_max\":\n",
    "        min_val = np.min(x, axis=0)\n",
    "        max_val = np.max(x, axis=0)\n",
    "        y = (x - min_val)/(max_val-min_val)\n",
    "    elif \"mu_law\" in type_norm:\n",
    "        temp = type_norm.split(\"_\")\n",
    "        mu = float(temp[-1])\n",
    "        y = np.sign(x)*(np.log(1+mu*abs(x)))/(np.log(1+mu))\n",
    "    else:\n",
    "        raise TypeError(f'{type_norm} is not defined in type_norm')\n",
    "\n",
    "    return y\n",
    "\n",
    "x = np.arange(-0.01,0.01,0.00001)\n",
    "\n",
    "algo = [\"linear\",\"mu_law_0.1\",\"mu_law_1\",\"mu_law_256\"]\n",
    "y1 = normalization(x, type_norm=algo[1])\n",
    "y2 = normalization(x, type_norm=algo[2])\n",
    "y3 = normalization(x, type_norm=algo[3])\n",
    "\n",
    "plt.Figure(figsize=(4,4))\n",
    "plt.plot(x,x)\n",
    "plt.plot(x,y1)\n",
    "plt.plot(x,y2)\n",
    "plt.plot(x,y3)\n",
    "plt.grid()\n",
    "plt.legend(algo)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
